{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 – standard preprocessing pipeline. Steps are hardcoded in the code itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def main():\n",
    "    num_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"VarianceThreshold\", VarianceThreshold(threshold=0.1)),\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"-1\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 – different pipelines for different models. Code becomes messy as pipelines are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"-1\")),\n",
    "        (\"VarianceThreshold\", VarianceThreshold(threshold=0.1)),\n",
    "        (\"scalar1\", StandardScaler()),\n",
    "        (\"pca1\", PCA(n_components=2)),\n",
    "        (\"lr_classifier\", LogisticRegression(random_state=0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_dt = Pipeline(\n",
    "    [\n",
    "        (\"scalar2\", StandardScaler()),\n",
    "        (\"VarianceThreshold\", VarianceThreshold(threshold=0.1)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"-1\")),\n",
    "        (\"pca2\", PCA(n_components=2)),\n",
    "        (\"dt_classifier\", DecisionTreeClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_randomforest = Pipeline(\n",
    "    [\n",
    "        (\"scalar3\", StandardScaler()),\n",
    "        (\"pca3\", PCA(n_components=2)),\n",
    "        (\"rf_classifier\", RandomForestClassifier()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 – Hydra configuration file, for creating the pipeline from Example 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# Hydra config file for the decition_tree preprocessing steps\n",
    "_target_: hydra_sklearn_pipeline.make_pipeline\n",
    "\n",
    "#StepName:\n",
    "#    _target_: <class to initiating the step>\n",
    "#    param1: <step's first parameter>\n",
    "#    param2: <step's second parameter, etc.>\n",
    "\n",
    "steps_config: # use yaml list syntax to preserve to order\n",
    "    - StandardScaler:\n",
    "        _target_: sklearn.preprocessing.StandardScaler\n",
    "\n",
    "    - VarianceThreshold:\n",
    "        _target_: sklearn.feature_selection.VarianceThreshold\n",
    "        threshold: 0.1\n",
    "\n",
    "    - SimpleImputer:\n",
    "        _target_: sklearn.impute.SimpleImputer\n",
    "        strategy: 'constant'\n",
    "        fill_value: '-1'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4 – Function to create a sklearn-hydra pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def make_pipeline(steps_config: DictConfig) -> Pipeline:\n",
    "    \"\"\"Creates a pipeline with all the preprocessing steps specified in `steps_config`, ordered in a sequential manner\n",
    "\n",
    "    Args:\n",
    "        steps_config (DictConfig): the config containing the instructions for\n",
    "                                    creating the feature selectors or transformers\n",
    "\n",
    "    Returns:\n",
    "        [sklearn.pipeline.Pipeline]: a pipeline with all the preprocessing steps, in a sequential manner\n",
    "    \"\"\"\n",
    "    steps = []\n",
    "\n",
    "    for step_config in steps_config:\n",
    "\n",
    "        # retrieve the name and parameter dictionary of the current steps\n",
    "        step_name, step_params = step_config.items()[0]\n",
    "\n",
    "        # instantiate the pipeline step, and append to the list of steps\n",
    "        pipeline_step = (step_name, hydra.utils.instantiate(step_params))\n",
    "        steps.append(pipeline_step)\n",
    "\n",
    "    return Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5 – Configs hierarchy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "tree configs/ # from WSL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6 – config.yaml, which pointes to “decision_tree.yaml” when creating the preprocessing_pipelined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# @package _global_\n",
    "\n",
    "# specify here default preprocessing configuration\n",
    "defaults:\n",
    "    # can be any config file in the preprocessing_pipeline folder\n",
    "    - preprocessing_pipeline: decision_tree.yaml \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7 – Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "\n",
    "@hydra.main(config_path=\"configs/\", config_name=\"config.yaml\")\n",
    "def main(config: DictConfig):\n",
    "\n",
    "    preprocessing_pipeline = hydra.utils.instantiate(\n",
    "        config.preprocessing_pipeline, _recursive_=False\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:board]",
   "language": "python",
   "name": "conda-env-board-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}